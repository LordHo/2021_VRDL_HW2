{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from dataset import EvalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Weight of load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output as image with rectangle by model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def load_model():\n",
    "    model_path = os.path.join('model', f'faster-rcnn-{weight}.pkl')\n",
    "    return torch.load(model_path)\n",
    "\n",
    "def draw_ret(ax, box):\n",
    "    assert len(box) == 4\n",
    "    x, y = box[0], box[1]\n",
    "    width, height = (box[2]-box[0]), (box[3]-box[1])\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1,\n",
    "                                     edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_out_image():\n",
    "    image_dir = os.path.join('..', 'data', 'test')\n",
    "    print(f'image_dir: {image_dir}')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "\n",
    "    dataset = EvalDataset(image_dir)\n",
    "    data_loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    model = load_model()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    until = 30\n",
    "\n",
    "    pbar = tqdm(data_loader)\n",
    "    for i, (image, image_name) in enumerate(pbar):\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        # print(output)\n",
    "        output = output[0]\n",
    "\n",
    "        boxes = output['boxes']\n",
    "        labels = output['labels']\n",
    "        scores = output['scores']\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        title_message = [image_name[0]]\n",
    "        ax.imshow(transforms.ToPILImage()(np.squeeze(image)))\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if score > 0.75:\n",
    "                draw_ret(ax, box)\n",
    "                title_message.append(f'{label}:{100*score:.0f}%')\n",
    "        \n",
    "        # print(title_message)\n",
    "        ax.set_title(' '.join(title_message))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # if i+1 > until:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_out_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw rectangle by existed json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect_in_json():\n",
    "    def draw_ret(ax, box):\n",
    "        assert len(box) == 4\n",
    "        x, y = box[0], box[1]\n",
    "        width, height = box[2], box[3]\n",
    "        rect = patches.Rectangle((x, y), width, height, linewidth=1,\n",
    "                                        edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    from  PIL import Image\n",
    "    json_path = os.path.join(f'answer-{weight}.json')\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        answer = json.load(json_file)\n",
    "\n",
    "    image_dir = os.path.join('..', 'data', 'test')\n",
    "    print(f'image_dir: {image_dir}')\n",
    "\n",
    "    for i, item in enumerate(answer):\n",
    "        box = item['bbox']\n",
    "        label = item['category_id']\n",
    "        score = item['score']\n",
    "        if score > 0.9:\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            title_message = [str(item['image_id'])]\n",
    "            image = Image.open(os.path.join(image_dir, str(item['image_id'])+'.png'))\n",
    "            ax.imshow(image)\n",
    "            draw_ret(ax, box)\n",
    "            print(box)\n",
    "            title_message.append(f'{label}:{100*score:.0f}%')\n",
    "            \n",
    "            ax.set_title(' '.join(title_message))\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_rect_in_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output as json, by model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_out_json():\n",
    "    answer = []\n",
    "\n",
    "    image_dir = os.path.join('..', 'data', 'test')\n",
    "    print(f'image_dir: {image_dir}')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "\n",
    "    dataset = EvalDataset(image_dir)\n",
    "    data_loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    model = load_model()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # count = 0\n",
    "\n",
    "    pbar = tqdm(data_loader)\n",
    "    for i, (image, image_name) in enumerate(pbar):\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        output = output[0]\n",
    "\n",
    "        boxes = output['boxes']\n",
    "        labels = output['labels']\n",
    "        scores = output['scores']\n",
    "\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            if score > 0.75:\n",
    "                dict_ = {}\n",
    "                dict_['image_id'] = image_name[0].split('.')[0]\n",
    "                dict_['score'] = float(score)\n",
    "                if int(label) < 10:\n",
    "                    dict_['category_id'] = int(label)\n",
    "                else:\n",
    "                    dict_['category_id'] = 0\n",
    "                # print(box)\n",
    "                dict_['bbox'] = box\n",
    "                # {\n",
    "                #     \"image_id\": 117,\n",
    "                #     \"score\": 0.9752130508422852,\n",
    "                #     \"category_id\": 3,\n",
    "                #     \"bbox\": [\n",
    "                #         41.071231842041016,\n",
    "                #         8.766018867492676,\n",
    "                #         13.521903991699219,\n",
    "                #         25.68875789642334\n",
    "                #     ]\n",
    "                # },\n",
    "                answer.append(dict_)\n",
    "        # count += 1\n",
    "        # if count == 3:\n",
    "        #     break\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = eval_out_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform json format from (x1, y1, x2, y2) to (x1, y1, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in tqdm(range(len(answer))):\n",
    "    answer[r]['image_id'] = int(answer[r]['image_id'])\n",
    "    answer[r]['bbox'] = list(answer[r]['bbox'])\n",
    "    for i in range(4):\n",
    "        answer[r]['bbox'][i] = float(answer[r]['bbox'][i].cpu())\n",
    "    x1 = min(answer[r]['bbox'][0], answer[r]['bbox'][2])\n",
    "    x2 = max(answer[r]['bbox'][0], answer[r]['bbox'][2])\n",
    "    y1 = min(answer[r]['bbox'][1], answer[r]['bbox'][3])\n",
    "    y2 = max(answer[r]['bbox'][1], answer[r]['bbox'][3])\n",
    "    # width, height = (answer[r]['bbox'][2] - answer[r]['bbox'][0]), (answer[r]['bbox'][3] - answer[r]['bbox'][1])\n",
    "    width, height = (x2 - x1), (y2 - y1)\n",
    "    answer[r]['bbox'] = [x1, y1, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = sorted(answer, key=lambda x: x['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(answer, indent=4), file=open(f'answer-{weight}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json():\n",
    "    json_path = os.path.join(f'answer-{weight}.json')\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        answer = json.load(json_file)\n",
    "    \n",
    "    filtered_answer = []\n",
    "\n",
    "    score_filter = 0.9\n",
    "    for item in tqdm(answer):\n",
    "        if item['score'] > score_filter:\n",
    "            filtered_answer.append(item)\n",
    "    \n",
    "    print(json.dumps(filtered_answer, indent=4), file=open(f'answer-{weight}_{score_filter}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28477/28477 [00:00<00:00, 3556279.25it/s]\n"
     ]
    }
   ],
   "source": [
    "filter_json()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f6b1d647b04ef7a5020006bff80ccc5a4e177f5b826a976ee34dca3d6e5010"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('yun_pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
