{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from dataset import TrainDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# For training\n",
    "images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n",
    "labels = torch.randint(1, 91, (4, 11))\n",
    "images = list(image for image in images)\n",
    "targets = []\n",
    "for i in range(len(images)):\n",
    "    d = {}\n",
    "    d['boxes'] = boxes[i]\n",
    "    d['labels'] = labels[i]\n",
    "    targets.append(d)\n",
    "output = model(images, targets)\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "\n",
    "# optionally, if you want to export the model to ONNX:\n",
    "torch.onnx.export(model, x, \"faster_rcnn.onnx\", opset_version = 11)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    print(model, file=open('Faster-RCNN.txt', 'w'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_optimizer(model):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=1e-4)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def load_model():\n",
    "    model = torch.load(os.path.join('model', 'faster-rcnn-1580.pkl'))\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    mat_path = os.path.join('..', 'data', \"train answer\", 'digitStruct.mat')\n",
    "    print(f'mat_path: {mat_path}')\n",
    "    image_dir = os.path.join('..', 'data', 'train')\n",
    "    print(f'image_dir: {image_dir}')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "\n",
    "    dataset = TrainDataset(mat_path, image_dir)\n",
    "    # data_loader = torch.utils.data.DataLoader(\n",
    "    #     dataset, batch_size=2, shuffle=False, num_workers=4,\n",
    "    #     collate_fn=collate_fn)\n",
    "    data_loader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn)\n",
    "\n",
    "    # model = get_model(num_classes=11)\n",
    "    model = load_model()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    best_losses = None\n",
    "\n",
    "    epochs = 10\n",
    "    print(f'epochs: {epochs}')\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch {epoch} strat!')\n",
    "        epoch_losses = None\n",
    "\n",
    "        pbar = tqdm(data_loader)\n",
    "\n",
    "        # print(f'len dataset: {len(dataset)}')\n",
    "        for i, (images, targets) in enumerate(pbar):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            loss_message = []\n",
    "            for k in loss_dict.keys():\n",
    "                loss_message.append(f'{k}: {loss_dict[k]:.4f}')\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            if epoch_losses is None:\n",
    "                epoch_losses = losses\n",
    "            else:\n",
    "                epoch_losses += losses\n",
    "\n",
    "            loss_message.append(f'epoch_losses: {epoch_losses/i+1:.4f}')\n",
    "\n",
    "            pbar.set_description(', '.join(loss_message))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if best_losses is None or best_losses > epoch_losses:\n",
    "            best_losses = epoch_losses\n",
    "            torch.save(model, os.path.join('model', f'faster-rcnn-{best_losses:.0f}.pkl'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_path: ..\\data\\train answer\\digitStruct.mat\n",
      "image_dir: ..\\data\\train\n",
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10\n",
      "epoch 0 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab620\\Anaconda3\\envs\\yun_pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "loss_classifier: 0.0310, loss_box_reg: 0.1111, loss_objectness: 0.0002, loss_rpn_box_reg: 0.0067, epoch_losses: 1.1870: 100%|██████████| 8351/8351 [1:02:08<00:00,  2.24it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0432, loss_box_reg: 0.0908, loss_objectness: 0.0001, loss_rpn_box_reg: 0.0068, epoch_losses: 1.1860: 100%|██████████| 8351/8351 [1:04:00<00:00,  2.17it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0334, loss_box_reg: 0.1079, loss_objectness: 0.0006, loss_rpn_box_reg: 0.0055, epoch_losses: 1.1817: 100%|██████████| 8351/8351 [1:04:38<00:00,  2.15it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0419, loss_box_reg: 0.1152, loss_objectness: 0.0008, loss_rpn_box_reg: 0.0057, epoch_losses: 1.1768: 100%|██████████| 8351/8351 [1:04:27<00:00,  2.16it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0360, loss_box_reg: 0.0893, loss_objectness: 0.0000, loss_rpn_box_reg: 0.0068, epoch_losses: 1.1727: 100%|██████████| 8351/8351 [1:04:50<00:00,  2.15it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0459, loss_box_reg: 0.0894, loss_objectness: 0.0004, loss_rpn_box_reg: 0.0073, epoch_losses: 1.1725: 100%|██████████| 8351/8351 [1:04:51<00:00,  2.15it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0282, loss_box_reg: 0.1152, loss_objectness: 0.0052, loss_rpn_box_reg: 0.0058, epoch_losses: 1.1715: 100%|██████████| 8351/8351 [1:05:09<00:00,  2.14it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0274, loss_box_reg: 0.0892, loss_objectness: 0.0002, loss_rpn_box_reg: 0.0058, epoch_losses: 1.1717: 100%|██████████| 8351/8351 [1:05:09<00:00,  2.14it/s]\n",
      "  0%|          | 0/8351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 strat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_classifier: 0.0384, loss_box_reg: 0.0826, loss_objectness: 0.0030, loss_rpn_box_reg: 0.0052, epoch_losses: 1.1656: 100%|██████████| 8351/8351 [1:05:24<00:00,  2.13it/s]"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f6b1d647b04ef7a5020006bff80ccc5a4e177f5b826a976ee34dca3d6e5010"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('yun_pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
